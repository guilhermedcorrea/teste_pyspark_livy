{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Tutorial Base\n",
    "#https://stackoverflow.com/questions/73407882/access-in-memory-spark-dataframe-from-different-nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "APP_NAME = \"spark.data_processing_engine\"\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(APP_NAME) \\\n",
    "    .getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "\n",
    "schemaSnmp = StructType([\n",
    "    StructField(\"node-hostname\", StringType(), True),\n",
    "    StructField(\"event-time\", TimestampType(), True),\n",
    "    StructField(\"oid\", StringType(), True),\n",
    "    StructField(\"value\", StringType(), True)\n",
    "])\n",
    "\n",
    "result = spark.readStream \\\n",
    "    .option(\"sourceArchiveDir\", \"/var/datalake-archive\") \\\n",
    "    .option(\"cleanSource\", \"archive\") \\\n",
    "    .schema(schemaSnmp) \\\n",
    "    .json(\"/var/datalake/snmp-get\") \\\n",
    "    .writeStream \\\n",
    "    .queryName(\"snmpget\") \\\n",
    "    .format(\"parquet\") \\\n",
    "    .option(\"checkpointLocation\", \"/var/spark-map/snmp-get\") \\\n",
    "    .option(\"path\", \"/var/spark-map/snmp-get\") \\\n",
    "    .start()\n",
    "\n",
    "result.awaitTermination()\n",
    "result.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import time \n",
    "import datetime \n",
    "import logging\n",
    "\n",
    "\n",
    "APP_NAME = \"spark.data_processing_engine\"\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(APP_NAME) \\\n",
    "    .getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"node-hostname\", StringType(), True),\n",
    "    StructField(\"event-time\", TimestampType(), True),\n",
    "    StructField(\"oid\", StringType(), True),\n",
    "    StructField(\"value\", StringType(), True)\n",
    "])\n",
    "\n",
    "results = spark.readStream \\\n",
    "        .schema(schema) \\\n",
    "        .parquet(\"/var/spark-map/snmp-get/\") \\\n",
    "        .writeStream \\\n",
    "        .queryName(\"snmpget\") \\\n",
    "        .format(\"memory\") \\\n",
    "        .start()\n",
    "\n",
    "i = 0\n",
    "while i < 60:\n",
    "    x = spark.table(\"snmpget\").select(\"value\", \"oid\", \"`node-hostname`\", \"`event-time`\").orderBy(\"`event-time`\", ascending=False).head()\n",
    "    if (x == None):\n",
    "        print(\"Data may still be loading, give this approx 30 seconds\")\n",
    "    else: \n",
    "        print(f\"x = {x}\")\n",
    "    i = i+1\n",
    "    time.sleep(1)\n",
    "\n",
    "results.stop()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
